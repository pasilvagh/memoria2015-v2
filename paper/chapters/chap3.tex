\chapter{Marco Teórico - (In) Seguridad en el Browser}
\label{chap3:MT}


En esta sección se presentan los posibles ataques que un \textit{Browser} puede sufrir y que directamente podrían afectar al sistema con el que se comunica. Principalmente ahondaremos en los ataques en el \textit{Browser} relacionados a las técnicas de Ingeniería Social \cite{socEngineeering}. El escenario actual de los ataques en el \textit{browser} ha cambiado bastante, si es comparado a aquellos de la decada de los noventa. Cada día los Browsers son más robustos y difíciles de explotar, y por lo mismo los ataques de tipo \textit{drive-by downloads} o los basados en ejecución de código para vulnerar el sistema, cada vez son menores. Una nueva forma de ataque ha emergido y es bastante fácil de lograrlo, pues se basa en el engaño del usuario a realizar lo que el atacante desea. Una vez el usuario es engañado, el atacante puede lograr un control total tanto del \textit{Browser} o del Host, sin haber tenido que vulnerar el sistema \cite{Rajab2013,Labs2013} que aloja al \textit{Browser}. Desarrollos de sistemas críticos que interactuan a diario con diferentes usuarios en la red, deberían de ser los más preocupados de estos ataques pues atentan contra la confidencialidad, integridad y disponibilidad de los datos, tanto del usuario (personales) como los de los \textit{Stakeholders} involucrados.

\section{Social Engineering o Ingeniería Social}
\cite{socEngineeering} define este tipo de acción como: El acto de manipular una persona para realizar acciones que no son parte de los mejores intereses del \textit{blanco o víctima} (la misma persona/organización/etc u otra entidad). Un ataque de éste tipo puede darse de diversas maneras, no dejando la posibilidad de un encuentro físico o digital con el que realiza el engaño. Un ataque basado en ingeniería social, es uno que se aprovecha del comportamiento humano y la confianza de la víctima. En el contexto del Web Browser, el usuario engañado es la primera y última línea de defensa contra este tipo de ataques, pues un abuso en la confianza del usuario podría abrir las puertas al Host del \textit{Browser}, logrando un daño tanto del usuario como con los sistemas externos con los que interactúa.

Si pudieramos dividir los ataques de Social Engineering, podríamos encontrarnos con un panorama parecido al de la Figura \ref{fig:SEattack}. En esta figura es posible observar que los ataques de Clickjacking se encuentran afuera del ámbito de los ataques de  Ingeniería Social, esto es dado a que el usuario que está navegando, pudo haber accedido a una página web conocida por él, sin siquiera que el atacante haya sugestionado a éste. Sin embargo, Clickjacking puede terminar convirtiendose en un ataque de Social Engineering si se combina con otros procedimientos.

	\begin{figure}[h!t]
        \centering
        \includegraphics[scale=0.5]{figures/SEAttacks.png}
        \caption{Esquematización de ataques de tipo Social Engineering. Fuente: Elaboración Propia.}
        \label{fig:SEattack}
    \end{figure}

 	\subsection{Análisis de ataques}
	Según los estudios \cite{browSecPhish, Labs2013, rowSecSEMBlock} indican que el \textit{Browser} es la primera linea de defensa en contra de multiples amenazas en la Web. Sin embargo, esto se ve afectado bastante por la falta de educación de los usuarios que utilizan los navegadores y la constante evolución de las amenazas \cite{browSecPhish} Es por esto que muchos de los manufacturadores de browsers crean mecanismos de defensa \cite{Drake2011} que actuen al momento de solicitar una página, usando black o white list, sistemas de reputación \cite{Rajab2013} con avisos de alerta al usuario, para evitar que éste al menos tome la decisión de poder ingresar al sitio malicioso.

\section{Ataques y Amenazas}
Esta sección incluye algunos ataques posibles de realizar en un \textit{Browser} y que podrían afectar tanto directa como indirectamente a un sistema externo. Acá no incluiremos ataques en donde el Host ya ha sido vulnerado con anticipación, o aquellos que puedan correr software con los privilegios de un usuario del sistema Host, es decir, aquellos donde el Host ya ha sido controlado directamente por medio de alguna vulnerabilidad del sistema. En el caso anterior, los Browsers ya nada pueden hacer para detener un ataque de esa magnitud.

En el Top Ten \cite{owaspTopTen} de la OWASP (Open Web Application Security Project) - los diez riesgos de seguridad más importantes en Aplicaciones Web - se puede distinguir en el año 2013 los riesgos directamente relacionados a amenazas de seguridad en el \textit{Browser}. Algunos como: Injección (A1), Manejo de sesiones y autenticación roto (A2), XSS (A3) y uso de componentes con vulnerabilidades conocidas (A9), son los riesgos que las organizaciones podrían sufrir en sus sistemas cuando se realizan ciertos ataques en el \textit{Browser}.

En trabajos \cite{barth2008security, FirefoxThreatModel} se puede observar que existen ataques que pueden generar secuelas en otros sistemas, si es que el Navegador es afectado en primera instancia. Algunas amenazas existentes son:

\begin{enumerate}
	\item Compromiso de los componentes del Navegador (plugins incluídos) que poseen privilegios de usuario.
	\item Compromiso del Host/Sistema.
	\item Robo de datos en el tráfico.
	\item Compromiso de páginas web (y su data) de origenes distintos.
	\item Fijación de sesión o robo de ésta.
	\item Compromiso de los canales de comunicación del \textit{Browser}.
\end{enumerate}

Una lista (parcial) de ataques asociados a las amenazas anteriores son:

\subsection{Phishing}
Este ataque consta principalmente del engaño al usuario, confundiendolo a que visite una página deshonesta en vez de la que tenía pensado. En el último tiempo muchos de los ataques que actualmente están ocurriendo se han limitado al uso de técnicas de ingeniería social. Si bien los ataques basados en drive-by downloads y clickjacking siguen siendo de alto impacto, los atacantes parecen preferir los otros por la simplicidad de éste, pues no es necesario conocer realmente vulnerabilidades del \textit{Browser} para llevarlos a cabo. Sin embargo, el Phishing es una buena herramienta que permite generar muchos otros ataques, que son mucho más peligrosos. Un resultado obtenido dentro del experimento en \cite{browSecPhish}, menciona que la vida útil en promedio de un sitio de Phishing es de aproximadamente 26 horas. Esto principalmente es debido a que los sistemas de defensa, antes de saber si es malicioso o no, debe descubrir, validar y clasificar en el sistema de reputación, tan pronto como sea posible.

	\subsubsection{Instalación de Malware o Extensiones malignas}
	Un ataque de este tipo puede ser originado desde la ejecución de un ataque Phishing a una persona; en especial cuando se hace creer que lo que se va a instalar es completamente inofensivo. Sin embargo, el resultado de la aceptación de usuario a la instalación puede tener consecuencias bastante graves tanto en el Browser como en el Host, donde la mayoría de las veces el ataque puede terminar como un Man-in-the-Browser \cite{Utakrit2009, Dougan2012}. En la jerga de NSS Labs estos ataques son llamados SEM o Social Enginerring Malware, en el estudio \cite{rowSecSEMBlock} afirma que conocer la identidad de los atacantes que utilizan Social Engineering permite una mejor protección contra los SEM. El trabajo recomienda que las Empresas y grandes organizaciones deberían revisar los reportes de otros Laboratorios de Seguridad cuando seleccionan un tipo de Web Browser; Las empresas deben entender que el mercado de los Browsers no es estático y muchas amenazas aparecen constantemente. El estudio concluye que la Educación es un componente importante en la protección de SEM, pues aquellos usuarios que son capaces de identificar ataques de Ingeniería Social (SE), necesitan menos tecnologías para la protección de estos ataques.

	\subsubsection{Extensiones vulnerables}
	Muchas veces un ataque Phishing se aprovechará de las extensiones \textit{benign-but-buggy}, es decir, de extensiones que tienen un propósito benigno para el usuario que las usa, pero que un atacante puede aprovecharse de alguna vulnerabilidad \cite{Barth2010, Liu2012}. Además dependiendo del tipo de arquitectura que el Browser pueda tener, es posible que el atacante utilice una extensión que tenga permisos a ciertos recursos del Host o que pueda coludirse con otra extensión benigna para lograr un ataque en forma conjunta \cite{Saini2014}; donde lo peor de todo, es que el tráfico no será detectado como malicioso.

	\subsubsection{Ejecución de Código Javascript}
    Este tipo de ataques ocurren cuando es posible ejecutar un script en el interprete del cliente, de manera que pueda generar acciones maliciosas dentro del Browser del Cliente. Este tipo de ataque funciona muy bien, cuando el atacante desea que el Web Browser de la victima realice acciones en nombre del atacante, de tal manera que la identificación de este se haga casi imposible. En ciertas situaciones un atacante podría aprovecharse de alguna vulnerabilidad asociada a los modelos de seguridad que Javascript y DOM poseen, pues ambos son totalmente transversales. Javascript utiliza un modelo de seguridad en sus objetos basado en \textbf{Capabilities}, mientras que DOM refuerza el \textbf{Same Origin Policy} por medio del uso de un \textbf{Reference Monitor} para controlar el acceso de código de diversos \textbf{orígenes}. Es en esta situación donde podría llevarse a cabo la ejecución de código javascript aún cuando éste pueda ser de un \textbf{origen} distinto al receptor \cite{Barth2009}.

	\subsubsection{XSS - Cross-Site Scripting DOM}
	Es un ataque XSS en donde su \textit{payload} de ataque es ejecutado como resultado de la modificación del \textit{ambiente} DOM en el navegador de la víctima usado por el código script original; en consecuencia el código de cliente se ejecuta de una manera inesperada. El ataque Cross-Site Scripting (XSS) normalmente se asocia con ataques que afectan directamente al servidor, pero existe una tercera variedad que afecta directamente al navegador \cite{Singh2014} y que puede ser tan peligrosa como su forma \textit{Reflajada} o \textit{Almacenada}, esta es llamada XSS DOM o \textbf{tipo-0 XSS} \cite{XSSDOMOwasp, XSSDOM}. Un ejemplo de un simple XSS DOM puede verse en \cite{bugzillaXSSDOM}. Un UXSS o Universal XSS es un ataque más particular, y tiene la habilidad de ser gatillado al explotar una falla en el interior del Browser \cite{Paola2006}, a diferencia de otros XSS que buscan la vulnerabilidad dentro del Servidor Web al que se comunican.


	\subsubsection{Man in the \textit{Browser} (MitB)}
    Un Man in the Browser es una técnica utilizada por un atacante para poder leer o modificar datos que se envían entre el cliente Web y el Servidor que responde a las request. La diferencia sustancial entre un Man in the Browser (MitB) y un Man in the Middle (MitM) es el dominio que ataca, el primero es al nivel de la capa de aplicación, mientras que el segundo tiene que ver más con el canal de comunicación. \cite{Dougan2012} explica las grandes diferencias entre estos dos ataques, donde principalmente un MitB se inicia con un ataque Phishing que logra convencer al usuario de instalar alguna extensión o ejecutar una pieza de código \cite{Utakrit2009, Paola2006}, que permita al atacante estar entre el Browser y el Host, de tal manera que todas las solicitudes puedes ser escuchadas y modificadas dentro del mismo Host.




%\section{Mecanismos de Defensa del Host}
%	Dependiendo del Sistema Operativo, es posible encontrar diversos mecanismos de Defensa. Tanto Linux como Windows poseen mecanismos parecidos, donde se diferencia la implementación. Dado que la mayor parte de los usuarios en internet usan Windows (Figura \ref{fig:OS}) nos enfocaremos en éste para mostrar los mecanismos implementados en el Host.

%	\begin{figure}[h!t]
 %       \centering
  %      \includegraphics[scale=0.5]{figures/StatCounter-os-ww-yearly-2010-2015.png}
   %     \caption{Gráfico con porcentaje de tipo de sistemas operativos más usados. Fuente: \cite{statOS}}
    %    \label{fig:OS}
    %\end{figure}

    %\subsection{DEP/NX o Data Execution Prevention}

    %\subsectiob{ASLR o Address Space Layout Randomization}

    %\subsection{/GS (Buffer Security Check)}

    %\subsection{SafeSEH}

    %\subsection{Function Pointer Ofuscation}

    %\subsection{Export Address Table Access Filtering (EAF)}

    %\subsection{NULL page allocation}


\section{Mecanismos de Defensa del \textit{Browser}}

\subsection{Sandboxing}
    \label{chap3:Sandboxing}
    La idea es encapsular el área de mayor probabilidad de ataque en un espacio aislado, minimizando la superficie de ataque de un software. Sandboxing no es una técnica tan nueva, han existido sistemas que ya lo han incorporado. Ésta protección puede ser aplicada dependiendo del diseño del software, algunos ocupan Sandbox a nivel del sistema operativo como otros que ocupan al nivel del \textit{engine} de Javascript \cite{reis2009browser}. En el caso especial del \textit{Browser}, esta técnica es construida en el nivel más alto posible para un programa de usuario, lo que permite la separación de privilegios entregados por el sistema operativo al \textit{browser} y los subprocesos que corren dentro de éste. El atacante que se enfrente a un \textit{browser} que tenga este mecanismo de defensa, tendrá que realizar primero un \textit{bypass} encontrando una vulnerabilidad en el sandboxing del \textit{browser}. Existen diferentes técnicas para Sandboxing, todo depende del diseño del \textit{Browser}.

    En el desarrollo de \cite{barth2008security} se define un modelo de amenazas donde se enumeran las habilidades que debería de tener un atacante y los objetivos de estos, para así caracterizar y evaluar las propiedades de seguridad necesarias para evitar que los atacantes cumplan su objetivo. Una propiedad importante que hacen destacar en el estudio es cómo aislar ciertos procesos que pueden ser aprovechados por los atacantes y ofrece una forma para poder mitigar esto: Sandboxing. El Sandboxing de Google Chrome previene al atacante de leer o escribir en el sistema de archivos del usuario, dejando al Principal Web con los privilegios necesarios para parsear un HTML/XML y ejecutar código JavaScript. Sin embargo esta arquitectura no imposibilita al atacante a atacar otros sitios web si es que el Rendering Engine fue comprometido, lo que puede convertirse en una amenaza muy grande para otros sitios web.

    Mientras Google Chrome e Internet Explorer utilizan un Sandbox para sus procesos de Renderizado \cite{sandboxGC}, Firefox no ha realizado este trabajo siquiera en su versión monoproceso \cite{NeckoElectro}.



    \subsubsection{Google}
        El Sandbox de Google es una implementación propia y que también aprovecha las técnologías disponibles en el Sistema Operativo. La idea del Sandbox es restringuir el acceso o peticiones al sistema de archivos, de modo que la única manera es pidiendo a otro que realice el trabajo que el proceso dentro del Sandbox necesita.

        \begin{figure}[h!t]
            \centering
            \includegraphics[scale=0.5]{figures/sbox_top_diagram.png}
            \caption{Sandbox interno de Google Chrome/Chromium. Fuente: \cite{sandboxGC}}
            \label{fig:SandboxGC}
        \end{figure}

    \subsubsection{Internet Explorer}
        Un nuevo mecanismo para aislar procesos es introducido en Windows 8, llamado AppContainer, es el principal mecanismo usado por Enhanced Protected Mode para aislar y limitar los privilegios y capacidades de un proceso con Sandboxing.
        \begin{figure}[h!t]
            \centering
            \includegraphics[scale=0.5]{figures/sandboxIE.png}
            \caption{Sandbox interno de Internet Explorer. Fuente: \cite{Yason}}
            \label{fig:SandboxIE}
        \end{figure}

        \begin{figure}[h!t]
            \centering
            \includegraphics[scale=0.5]{figures/IEProtectedMode.jpg}
            \caption{Sandbox, Protected Mode. Fuente: \cite{Crowley2010}}
            \label{fig:SandboxIE2}
        \end{figure}
        La idea principal del Sandboxing en IE es restringuir el acceso de escritura a objetos \textit{asegurables}, como procesos, archivos o llaves de registro que sean de niveles de integridad mayor \cite{Colvin2010}. El proceso mismo de Internet Explorer posee un nivel de integridad baja, por lo tanto la única manera de modificar algo es cuando se le pregunta explicitamente al usuario y éste lo permite.



 \subsection{Aislación de Procesos}
    Cuando hablamos de Aislación de Procesos, nos referimos a cómo los Navegadores realizan la separación del contenido que será renderizada. Esto es dado que si no se es cuidadoso, scripts de otro \textbf{Origen} podrían intervenir con una página benigna y tomar control de ésta. Google Chrome aisla el contenido de cada recurso que el usuario pide, por medio de la instanciación de siteinstance-per-process \cite{Reis2009}, aunque durante este último tiempo están tratando de mejorarlo a site-per-process \cite{GoogleChromeIsolation}. Esto último significaría que cada página y frame tendría su propio proceso, separando completamente los espacios de memoria que cada componente de la página usaria al ser renderizada. Esto permite disminuir tanto la superficie de ataque, como incrementar la estabilidad del Browser, si es que algún componente provoca algún fallo. Firefox \cite{FirefoxThreatModel}, por su parte, promete que en futuras versiones del Browser multiproceso, diferentes Tabs podrán correr en diferentes procesos de acuerdo a su dominio, pero por ahora todas las tabs de contenidos comparten un solo process de Content process.

    La Aislación de Procesos es importante pues permite proveer de Seguridad, Sensibilidad, Estabilidad y Confiabilidad, pues al separar el proceso los espacios de memoria de cada procesos pueden ser random (si ALSR está activado \cite{Drake2011}). Además al separar en procesos, se están crendo distintas tareas que el sistema operativo se encargará de distribuir y computar de forma paralela. Y si alguno de estos procesos se cae, el proceso principal y todos los asociados, no deberían de ser afectados. Internet Explorer no indica que tipo de aislación provee en su documentación, pero debe ser algo entre lo que Google Chrome y Firefox proponen, pues los resultados que ellos han obtenido son alentadores.
    
    Uno de los pasos que ha tomado Google Chrome/Chromium y que Firefox va para el mismo rumbo con la API \textbf{WebExtension} \cite{AddONFirefox}, es la aislación de las extensiones del contenido de la página, tal como lo sugiere \cite{Barth2010}. Donde un Content script es el que podrá cambiar el contenido del DOM, pero no será capaz de afectar a las Tabs, Bookmarks de otro Tab y menos el sistema de archivos, a excepción que encuentre una vulnerabilidad que se lo permita.
    
    %GC: Barth2010, Barth2009SecureFrame, Reis2009, barth2008security
    %IE: Crowley2010, Yason
    %Todo: Drake2011, Saini2014, Silic2010

 \subsection{Blacklist y Whitelist de sitios web}

    El estudio \cite{browSecPhish} explica las más comunes y efectivas amenazas de seguridad que los usuarios hoy en día se enfrentan, entre ellas están el Software Engineering Malware y el Phishing. Un experimento es llevado a cabo en este estudio, con evidencia empiricamente validada y obtenida por NSS durante 12 días de continuo testing. Se obtuvo como resultado que Safe Browsing de Google Chrome provee una mejor protección contra ataques de tipo Phishing si es comparado con SmartScreen de Internet Explorer. Estos mecanismos poseen la habilidad para alertar a la posible víctima, de  que están a punto de pedir un recurso que puede ser malicioso. Una de las conclusiones del estudio \cite{rowSecSEMBlock} es que afirma que la tecnología de Google Safe Browsing no provee una protección adecuada para SEM, pero tecnologías basadas en CAMP ayudan bastante.

    Tanto Google como Firefox usan Safe Browsing para investigar si un cierto recurso, detrás de la URL pedida, es posible que se trate de un Phishing. Ambos tienen listas negras que se van actualizando muchas veces en el día, el menos 2 veces por hora. Esto permite disminuir la cantidad de ataques de éste tipo, pero lamentablemente el dinamismo de éste tipo de ataque a veces hace imposible tener una lista de todos los sitios manipulados.

    \cite{Rajab2013} utiliza una Whitelist dentro del cliente para limitar la cantidad de peticiones que se reciban desde todos los Navegadores que necesitan información sobre un binario, que posiblemente pueda o no ser un Malware.
        %GC y Firefox
    Internet Explorer utiliza URL Filtering, con el SmartScreen, que permite obtener una buena protección contra Social Engineering Malware \cite{rowSecSEMBlock} a diferencia de los otros manufacturados de navegadores.
    %\cite{Crowley2010, Colvin2010}

 \subsection{Sistemas de Reputación}
    %Agregar que estos s complementar con blacklist y a veces whitelist (GC)
    Cada vez que un usuario desea un recurso, por medio de su URL, el usuario podría no saber que detrás de ese \textit{path} puede haber una amenaza. Un sistema de reputación trabaja en base a los distintos tipos de binarios que un usuario podría llegar a descargar, ya sea un archivo muy descagado que podría estar disfrazado como una imagen y en verdad se trata de un virus, o simplemente un pdf que es descargado por un grupo de alumnos de un curso con poca concurrencia. La idea detrás es tener un sistema centralizado que se encarga de dar una \textbf{reputación} al binario, dependiendo de la técnica usada. Tanto Internet Explorer como Google Chrome utilizan este tipo de sistema, pero cada uno lo implemente de distinta manera. Un buen sistema basado en Reputación es aquel que es preciso y rápido, de manera que sea posible de obtener altos porcentajes de detección (efectividad).

    El estudio \cite{rowSecSEMBlock} realizado por NSS Labs, hizo una experimentación de la capacidad de detección y bloqueo de Malware en los Browser más conocidos, entre ellos Firefox, Internet Explorer y Google Chrome. Se usaron 657 muestras de Socially Engineering Malware o SEM (Malware basados en Ingeniería Social), que fueron capturados por el laboratorio dentro de 14 días. Los ataques basados en SEM usan diferentes métodos para poder engañar a los usuarios. Uno de los puntos que dejan claro, es que el fator primario es el Web Browser, dado que es la primera linea de defensa de los usuarios en contra de la mayoría de los ataques SEM. El test realizado dentro de la experimentación demostró que Internet Explorer bloqueaba casi un \(99,9\%\) de los SEM sacados de la muestra usadas dentro del test. Google Chrome le sigue a IE con la mejor detección de Malware y otros Browser con tecnologías basadas en Cloud (KingSoft Antivirus), generan una mejor detección que Firefox (\(4,2\%\)). La alta detección y bloqueo obtenido tanto por Internet Explorer y Google Chrome/Chromium, es gracias a las tecnologías SmartScreen URL Filtering (filtro de URL, como black list) y Application Reputation, Chrome por su parte usa Safe Browsing API y Download Protection para resguardarse. Sin embargo, Internet Explorer no depende tanto en su Sistema de Reputación así como lo realiza Google Chrome, donde el \(2,9\%\) del \(99,9\%\) de la detección de IE es basada en la técnología CAMP y Google Chrome detecta \(66,5\%\) del \(70,7\%\) con su Download Protection. Ésto último significa para Google Chrome/Chromium, que su sistemas de Reputación es su mejor protección contra Malware. 

    %\subsubsection{Google Download - Google Chrome/Chromium}
        %Ocupar referencias de NSS para los resultados obtenidos
    %\subsubsection{SmartScreen - Internet Explorer}


 %\subsection{Filtros XSS}
  %  Los Filtros XSS son una medida preventiva contra posibles ataques XSS insertados en la response del servidor. Principalmente se encarga de prevenir XSS de tipo Reflejado o Almacenado, pues los tipo DOM podría ocupar técnicas para 
    %Google e IE
    %Firefox ocupa 3rd party
    %Vulnerabilidades mencionadas \cite{Bates2010}y la solución del paper es crear un filtro que detenga los ataques antes de que sean interpretados por el Renderer
 %\subsection{Safe Sanitization}

 %\subsection{AdBlocker}

 \subsection{Actualizaciones Periódicas en Background}
 Tanto Google Chrome \cite{reis2009browser} como Firefox realizan actualizaciones automáticas periódicas del Navegador, para reducir la ventana de posible vulnerabilidades que pueda tener una versión. Parte importante de esto es que este proceso no fastidia al usuario y permite que se instale a penas el browser se cierra, para que en la próxima sesión sea posible usar la nueva.

